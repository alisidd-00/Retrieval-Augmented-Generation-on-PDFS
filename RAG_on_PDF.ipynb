{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Installing Required Dependencies**"
      ],
      "metadata": {
        "id": "pt_bCxurVlpp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iG2gZqPwLEDc",
        "outputId": "f67d94ca-c2a5-43f3-cb37-cbf4a96cb925"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.1.9-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m997.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain\n",
            "  Downloading langchain-0.2.5-py3-none-any.whl (974 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.6/974.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-community\n",
            "  Downloading langchain_community-0.2.5-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core\n",
            "  Downloading langchain_core-0.2.9-py3-none-any.whl (321 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.8/321.8 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai<2.0.0,>=1.26.0 (from langchain-openai)\n",
            "  Downloading openai-1.35.3-py3-none-any.whl (327 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.4/327.4 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.1-py3-none-any.whl (23 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.81-py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.1/127.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.4.1)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (24.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.26.0->langchain-openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.5.15)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain-openai) (1.2.1)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain-openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain-openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: faiss-gpu, PyPDF2, orjson, mypy-extensions, marshmallow, jsonpointer, h11, typing-inspect, tiktoken, jsonpatch, httpcore, langsmith, httpx, dataclasses-json, openai, langchain-core, langchain-text-splitters, langchain-openai, langchain, langchain-community\n",
            "Successfully installed PyPDF2-3.0.1 dataclasses-json-0.6.7 faiss-gpu-1.7.2 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.5 langchain-community-0.2.5 langchain-core-0.2.9 langchain-openai-0.1.9 langchain-text-splitters-0.2.1 langsmith-0.1.81 marshmallow-3.21.3 mypy-extensions-1.0.0 openai-1.35.3 orjson-3.10.5 tiktoken-0.7.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-openai langchain langchain-community langchain-core faiss-gpu PyPDF2\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Required Modules**"
      ],
      "metadata": {
        "id": "1U_7S55BVtMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_openai import OpenAI, OpenAIEmbeddings\n",
        "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "from PyPDF2 import PdfReader"
      ],
      "metadata": {
        "id": "MQiNzpGgLjUP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting Environment Variable for API key ( Set your own to ensure working )**"
      ],
      "metadata": {
        "id": "Eq86_BeSV9mI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n"
      ],
      "metadata": {
        "id": "ahkeO6N2PGtE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Helper Functions**"
      ],
      "metadata": {
        "id": "GTk0LRU-VyLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pdf_content(documents):\n",
        "    \"\"\"\n",
        "    Extracts and concatenates text from a list of PDF documents.\n",
        "\n",
        "    Parameters:\n",
        "    documents (list): A list of paths to PDF documents.\n",
        "\n",
        "    Returns:\n",
        "    str: A single string containing the extracted text from all the provided PDF documents.\n",
        "    \"\"\"\n",
        "    raw_text = \"\"  # Initialize an empty string to hold the extracted text\n",
        "\n",
        "    for document in documents:  # Iterate through each document path in the provided list\n",
        "        pdf_reader = PdfReader(document)  # Create a PdfReader object for the current document\n",
        "\n",
        "        for page in pdf_reader.pages:  # Iterate through each page in the current document\n",
        "            raw_text += page.extract_text()  # Extract text from the current page and append it to raw_text\n",
        "\n",
        "    return raw_text  # Return the concatenated text from all the documents\n"
      ],
      "metadata": {
        "id": "SsF0BqbAOPdl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_chunks(text):\n",
        "    \"\"\"\n",
        "    Splits a given text into smaller chunks for easier processing.\n",
        "\n",
        "    Parameters:\n",
        "    text (str): The text to be split into chunks.\n",
        "\n",
        "    Returns:\n",
        "    list: A list of text chunks.\n",
        "    \"\"\"\n",
        "    # Create a CharacterTextSplitter object with specified parameters:\n",
        "    # - separator: the character used to split the text (newline character in this case)\n",
        "    # - chunk_size: the maximum number of characters in each chunk\n",
        "    # - chunk_overlap: the number of overlapping characters between consecutive chunks\n",
        "    # - length_function: function to calculate the length of the text (using the len function here)\n",
        "    text_splitter = CharacterTextSplitter(\n",
        "        separator=\"\\n\",\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200,\n",
        "        length_function=len\n",
        "    )\n",
        "\n",
        "    # Split the text into chunks using the text splitter\n",
        "    text_chunks = text_splitter.split_text(text)\n",
        "\n",
        "    # Return the list of text chunks\n",
        "    return text_chunks\n"
      ],
      "metadata": {
        "id": "pBpH8pUVOT6F"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings(chunks):\n",
        "    \"\"\"\n",
        "    Generates vector embeddings for a list of text chunks and stores them in a FAISS index.\n",
        "\n",
        "    Parameters:\n",
        "    chunks (list): A list of text chunks to be embedded.\n",
        "\n",
        "    Returns:\n",
        "    FAISS: A FAISS index containing the vector embeddings of the text chunks.\n",
        "    \"\"\"\n",
        "    # Create an OpenAIEmbeddings object to generate embeddings for the text chunks\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "\n",
        "    # Use the FAISS library to create a vector storage index from the text chunks and their embeddings\n",
        "    vector_storage = FAISS.from_texts(texts=chunks, embedding=embeddings)\n",
        "\n",
        "    # Return the FAISS index containing the vector embeddings\n",
        "    return vector_storage\n"
      ],
      "metadata": {
        "id": "dNnwdc3TOXhl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def start_conversation(vector_embeddings):\n",
        "    \"\"\"\n",
        "    Initializes a conversational retrieval chain with a language model and memory for context.\n",
        "\n",
        "    Parameters:\n",
        "    vector_embeddings (FAISS): A FAISS index containing vector embeddings for the text chunks.\n",
        "\n",
        "    Returns:\n",
        "    ConversationalRetrievalChain: A conversational retrieval chain object for handling interactive Q&A.\n",
        "    \"\"\"\n",
        "    # Create a ChatOpenAI object to use as the language model (LLM) for the conversation\n",
        "    llm = ChatOpenAI()\n",
        "\n",
        "    # Create a ConversationBufferMemory object to store and manage the conversation history\n",
        "    # - memory_key: the key under which the conversation history is stored\n",
        "    # - return_messages: whether to return the conversation messages\n",
        "    memory = ConversationBufferMemory(\n",
        "        memory_key='chat_history',\n",
        "        return_messages=True\n",
        "    )\n",
        "\n",
        "    # Create a ConversationalRetrievalChain object to handle the retrieval-based conversational interaction\n",
        "    # - llm: the language model to be used for generating responses\n",
        "    # - retriever: the retriever object created from the vector embeddings to find relevant information\n",
        "    # - memory: the memory object to store the conversation history\n",
        "    conversation = ConversationalRetrievalChain.from_llm(\n",
        "        llm=llm,\n",
        "        retriever=vector_embeddings.as_retriever(),\n",
        "        memory=memory\n",
        "    )\n",
        "\n",
        "    # Return the initialized conversational retrieval chain\n",
        "    return conversation\n"
      ],
      "metadata": {
        "id": "Siv-wvakOeda"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query_system(conversation, question):\n",
        "    \"\"\"\n",
        "    Queries the conversational retrieval system with a given question and returns the answer.\n",
        "\n",
        "    Parameters:\n",
        "    conversation (ConversationalRetrievalChain): The conversational retrieval chain object.\n",
        "    question (str): The question to be asked.\n",
        "\n",
        "    Returns:\n",
        "    str: The answer provided by the conversational retrieval system.\n",
        "    \"\"\"\n",
        "    # Pass the question to the conversation object and get the response\n",
        "    response = conversation({\"question\": question})\n",
        "\n",
        "    # Return the answer from the response\n",
        "    return response[\"answer\"]\n"
      ],
      "metadata": {
        "id": "noziYE4dPQCR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calling Functions to create Embeddings of Document**"
      ],
      "metadata": {
        "id": "WwFKEoEiWHQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_paths = [\"/content/RAG Input Doc.pdf\", \"/content/usig_sports_rules_-_cricket.pdf\"]\n"
      ],
      "metadata": {
        "id": "Z-uCBfzRzjVW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_texts = [get_pdf_content([path]) for path in document_paths]\n",
        "combined_text = \" \".join(document_texts)  # Combine texts from all documents\n",
        "text_chunks = get_chunks(combined_text)\n",
        "vector_embeddings = get_embeddings(text_chunks)\n",
        "conversation = start_conversation(vector_embeddings)\n"
      ],
      "metadata": {
        "id": "hA722GZGO-v_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answering questions using RAG**"
      ],
      "metadata": {
        "id": "XM3OnOPJWN7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**These are some of the sample quetions which I will be typing in and asking**"
      ],
      "metadata": {
        "id": "9HZtllKMBisi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    \"Which paper received the highest number of stars per hour?\",\n",
        "    \"What is the focus of the 'MeshAnything' project?\",\n",
        "    \"Which paper discusses the integration of Large Language Models with Monte Carlo Tree Search?\",\n",
        "    \"What advancements does the 'VideoLLaMA 2' paper propose?\",\n",
        "    \"Which paper was published most recently?\",\n",
        "    \"Identify a paper that deals with language modeling and its scalability\",\n",
        "    \"Which paper aims at improving accuracy in Google-Proof Question Answering?\",\n",
        "    '''List the categories covered by the paper titled 'TextGrad: Automatic \"Differentiation\" via Text'.''',\n",
        "    \"What are umpires in cricket?\",\n",
        "    \"How many overs are there in a T20 match?\",\n",
        "    \"What are boundary decisions\",\n",
        "    \"What happens when match is a tie\",\n",
        "    \"How many overs can a bowler bowl?\"\n",
        "]"
      ],
      "metadata": {
        "id": "qeJJmewoPfeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    question = input(\"Enter your question (or 'exit' to quit): \")\n",
        "    if question.lower() == 'exit':\n",
        "        break\n",
        "    response = conversation({\"question\": question})\n",
        "    print(f\"Answer: {response['answer']}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxT7Eq_kA4jw",
        "outputId": "82bcb42a-0b6f-4f91-af77-cf28b81ed477"
      },
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your question (or 'exit' to quit): Which paper received the highest number of stars per hour?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer: The paper \"Scalable MatMul-free Language Modeling\" by ridgerchu/matmulfreellm received the highest number of stars per hour with 2,140 stars per hour.\n",
            "\n",
            "Enter your question (or 'exit' to quit): What is the focus of the 'MeshAnything' project?\"\n",
            "Answer: The focus of the 'MeshAnything' project is on Artist-Created Mesh Generation with Autoregressive Transformers.\n",
            "\n",
            "Enter your question (or 'exit' to quit): Which paper discusses the integration of Large Language Models with Monte Carlo Tree Search?\n",
            "Answer: The paper that discusses the integration of Large Language Models with Monte Carlo Tree Search is titled \"Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B\" by trotsky1997/mathblackbox.\n",
            "\n",
            "Enter your question (or 'exit' to quit): What advancements does the 'VideoLLaMA 2' paper propose?\n",
            "Answer: The \"VideoLLaMA 2\" paper proposes advancements in spatial-temporal modeling and audio understanding in Video Large Language Models (Video-LLMs) intended to enhance performance in video and audio-oriented tasks.\n",
            "\n",
            "Enter your question (or 'exit' to quit): Which paper was published most recently?\n",
            "Answer: The most recent paper that was published is \"TextGrad: Automatic 'Differentiation' via Text,\" published on 11 Jun 2024.\n",
            "\n",
            "Enter your question (or 'exit' to quit): Identify a paper that deals with language modeling and its scalability\n",
            "Answer: The paper titled \"Scalable MatMul-free Language Modeling\" deals with language modeling and its scalability.\n",
            "\n",
            "Enter your question (or 'exit' to quit): Which paper aims at improving accuracy in Google-Proof Question Answering?\n",
            "Answer: The paper titled \"TextGrad: Automatic 'Differentiation' via Text\" aims at improving accuracy in Google-Proof Question Answering.\n",
            "\n",
            "Enter your question (or 'exit' to quit): List the categories covered by the paper titled 'TextGrad: Automatic \"Differentiation\" via Text'\n",
            "Answer: The categories covered by the paper titled 'TextGrad: Automatic \"Differentiation\" via Text' are Decision Making and GSM8K +2.\n",
            "\n",
            "Enter your question (or 'exit' to quit): What are umpires in cricket?\n",
            "Answer: Umpires in cricket are officials responsible for making decisions during a cricket match. They are responsible for making judgments on aspects such as LBW (leg before wicket), catches, stumpings, run-outs, and other scenarios that occur during the game. The main umpires on the field work together to ensure the match is played fairly and within the rules of the game.\n",
            "\n",
            "Enter your question (or 'exit' to quit): What are umpires in cricket?\n",
            "Answer: In cricket, umpires are individuals responsible for making decisions and enforcing the rules during a cricket match. They oversee the game, make decisions on aspects like LBW (Leg Before Wicket), dismissals, boundaries, wides, no-balls, and more. They ensure fair play and are crucial to the smooth running of a match.\n",
            "\n",
            "Enter your question (or 'exit' to quit): How many overs are there in a T20 match?\n",
            "Answer: There are 20 overs in each innings of a T20 match.\n",
            "\n",
            "Enter your question (or 'exit' to quit): How many overs can a bowler bowl?\n",
            "Answer: A bowler can bowl a maximum of four (4) overs in a T20 match.\n",
            "\n",
            "Enter your question (or 'exit' to quit): What happens when match is a tie\n",
            "Answer: In cricket, if a Twenty20 match ends in a tie during the preliminary rounds, the match will be considered a tie. However, in the playoffs, if a match ends in a tie, the tie will be broken with a one (1) over per side \"Eliminator\" or \"Super Over.\" Each team nominates three (3) batsmen and one (1) bowler to play a one-over mini-match, and the team with the higher score from their Super Over wins. If the scores are still tied after the Super Over, the team with the most boundaries combined from both innings will be declared the winner.\n",
            "\n",
            "Enter your question (or 'exit' to quit): What are boundary decisions\n",
            "Answer: Boundary decisions in cricket refer to situations where the on-field umpire may consult with the square leg umpire to determine whether a fieldsman had any part of his body in contact with the ball when touching or crossing the boundary line, or to confirm if a four or a six had been scored. This consultation is done immediately, and once a decision is made, it cannot be changed.\n",
            "\n",
            "Enter your question (or 'exit' to quit): exit\n"
          ]
        }
      ]
    }
  ]
}